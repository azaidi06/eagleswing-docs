---
title: "Pipeline Flow"
subtitle: "How data moves from phone to analysis"
---

## S3 Layout

All data lives in `golf-swing-data` with a golfer-first key structure:

```
{golfer}/
â”œâ”€â”€ raw/          # Original .MOV uploads (iPhone HEVC 10-bit VFR)
â”œâ”€â”€ processed/    # Transcoded .mp4 (H.264 CFR yuv420p)
â”œâ”€â”€ keypoints/    # ViTPose .pkl files (17 keypoints per frame)
â”œâ”€â”€ detection/    # Swing detection .json (backswing + contact frames)
â”œâ”€â”€ fingers/      # Finger prediction .json
â”œâ”€â”€ frames/       # Extracted JPGs with skeleton overlay
â”œâ”€â”€ output/       # Grids, signal plots, hand crops
â””â”€â”€ analysis/     # Biomechanical comparison plots + AI text
```

## Inter-Stage Messaging

Stages are connected via **S3 event notifications â†’ SQS**, with no orchestrator:

```{mermaid}
sequenceDiagram
    participant Phone
    participant S3
    participant SQS
    participant EC2
    participant Lambda1 as swing_detection
    participant Lambda2 as post_processing

    Phone->>S3: Upload .MOV to /raw/
    S3->>SQS: S3 event (suffix .MOV/.mp4)
    SQS->>EC2: worker.py polls
    EC2->>S3: Upload .mp4 to /processed/
    EC2->>S3: Upload .pkl to /keypoints/
    S3->>Lambda1: S3 event (suffix .pkl)
    Lambda1->>S3: Upload .json to /detection/
    S3->>Lambda2: S3 event (suffix .json)
    Lambda2->>S3: Upload to /fingers/, /frames/, /output/
```

Each stage fires-and-forgets to S3, and the next stage picks it up via event triggers. No central coordinator.

## Path Guards & Idempotency

The label worker has two safety mechanisms:

**Path guards** â€” only processes keys matching `/raw/` or `/processed/`:

```{python}
#| eval: false
# From worker.py â€” process_message()
if "/raw/" not in key and "/processed/" not in key:
    logger.info("Skipping non-raw/processed key: %s", key)
    return
```

**Idempotency** â€” skips if .pkl already exists:

```{python}
#| eval: false
# Checks S3 before processing
pkl_key = key.replace("/raw/", "/keypoints/").replace(".MOV", ".pkl")
if s3_object_exists(bucket, pkl_key):
    logger.info("Already labeled: %s", pkl_key)
    return
```

## Timing Breakdown

For a 5-min 60fps iPhone video (~18,000 frames, 168 MB raw):

```{python}
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use("Agg")

stages = ["S3 download", "Transcode\n(NVENC)", "Labeling\n(turbo)", "S3 upload", "Swing\ndetect", "Post\nprocess"]
times = [15, 74, 313, 35, 13, 5]
colors = ["#95a5a6", "#f39c12", "#e74c3c", "#95a5a6", "#3498db", "#3498db"]

fig, ax = plt.subplots(figsize=(10, 3))
bars = ax.barh(stages, times, color=colors, edgecolor="white", height=0.6)
ax.set_xlabel("Seconds")
ax.set_title("Per-video processing time (5-min 60fps, g6.2xlarge)")
ax.invert_yaxis()

for bar, t in zip(bars, times):
    ax.text(bar.get_width() + 3, bar.get_y() + bar.get_height()/2, f"{t}s", va="center", fontsize=9)

plt.tight_layout()
plt.show()
```

| Color | Meaning |
|-------|---------|
| ðŸŸ  Orange | GPU hardware (NVENC/NVDEC) |
| ðŸ”´ Red | GPU compute (CUDA, the bottleneck) |
| âšª Gray | Network I/O |
| ðŸ”µ Blue | Lambda CPU |

## Cold Start

First video on a fresh instance incurs a one-time cold start:

| Phase | Time | Why |
|-------|------|-----|
| Boot + user-data | 20s | cloud-init, S3 script pull |
| Python imports | 91s | EBS lazy-loading from snapshot (~12 MB/s) |
| Model load | 15s | Local checkpoint files |
| **Total** | **~2.1 min** | Amortized over all videos in session |

After cold start, inductor compiled models are cached on disk. `deploy.sh` uses `cmp -s` before overwriting worker scripts to preserve file mtimes â†’ inductor cache stays valid across deploys.
