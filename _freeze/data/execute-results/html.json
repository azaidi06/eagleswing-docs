{
  "hash": "5b98124b9404558b5737986524a975e8",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Data Formats\"\nsubtitle: \"PKL structure, JSON schemas, and keypoint conventions\"\n---\n\n## PKL Keypoint Files\n\nThe core data artifact. One per video, produced by `label_videos/worker.py`.\n\n::: {#071f3ad4 .cell execution_count=1}\n``` {.python .cell-code}\n# Structure:\n{\n    \"frame_0\": {\n        \"keypoints\": np.ndarray(17, 2),       # COCO-17 (x, y) per frame\n        \"keypoint_scores\": np.ndarray(17,),    # Confidence [0, 1] per joint\n        \"bbox\": [x1, y1, x2, y2]              # Person bounding box\n    },\n    \"frame_1\": {...},\n    ...\n    \"__meta__\": {\n        \"fps\": 60.0,\n        \"total_frames\": 3000,\n        \"width\": 1080,\n        \"height\": 1920,\n        \"n_pkl_frames\": 3000\n    }\n}\n```\n:::\n\n\n### Inspecting a Real PKL\n\n::: {#eec6315c .cell execution_count=2}\n``` {.python .cell-code}\nimport pickle, pathlib, numpy as np\n\nroot = pathlib.Path(\"..\").resolve()\npkls = sorted(root.glob(\"test_trials/**/keypoints/*.pkl\"))\n\nif pkls:\n    pkl_path = pkls[0]\n    with open(pkl_path, \"rb\") as f:\n        data = pickle.load(f)\n\n    meta = data.get(\"__meta__\", {})\n    frame_keys = sorted([k for k in data if k != \"__meta__\"],\n                        key=lambda k: int(k.split(\"_\")[1]))\n\n    print(f\"File: {pkl_path.name}\")\n    print(f\"Frames: {len(frame_keys)}\")\n    print(f\"Metadata: {meta}\")\n    print(f\"\\nSample frame ({frame_keys[0]}):\")\n\n    sample = data[frame_keys[0]]\n    kp = np.array(sample[\"keypoints\"])\n    scores = np.array(sample[\"keypoint_scores\"])\n\n    print(f\"  Keypoints shape: {kp.shape}\")\n    print(f\"  Score range: [{scores.min():.3f}, {scores.max():.3f}]\")\n    print(f\"  Bbox: {sample.get('bbox', 'N/A')}\")\nelse:\n    print(\"No sample pkl files found\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nFile: IMG_1016.pkl\nFrames: 19750\nMetadata: {'fps': 59.94005994005994, 'total_frames': 19750, 'width': 1080, 'height': 1920, 'n_pkl_frames': 19750}\n\nSample frame (frame_0):\n  Keypoints shape: (17, 2)\n  Score range: [0.014, 0.061]\n  Bbox: ([226.82351684570312, 920.984130859375, 241.9730224609375, 971.822998046875],)\n```\n:::\n:::\n\n\n## COCO-17 Keypoint Map\n\n::: {#fa39c6f6 .cell execution_count=3}\n\n::: {.cell-output .cell-output-stdout}\n```\n   0: Nose\n   1: Left Eye\n   2: Right Eye\n   3: Left Ear\n   4: Right Ear\n   5: Left Shoulder\n   6: Right Shoulder\n   7: Left Elbow\n   8: Right Elbow\n   9: Left Wrist ← primary swing signal\n  10: Right Wrist ← primary swing signal\n  11: Left Hip\n  12: Right Hip\n  13: Left Knee\n  14: Right Knee\n  15: Left Ankle\n  16: Right Ankle\n```\n:::\n:::\n\n\n## Detection JSON\n\nProduced by `swing_detection/lambda_handler.py`, stored at `{golfer}/detection/{video}.json`.\n\n::: {#ec4bfb63 .cell execution_count=4}\n``` {.python .cell-code}\n{\n    \"video_name\": \"IMG_1016\",\n    \"golfer\": \"stef\",\n    \"fps\": 60.0,\n    \"total_frames\": 5821,\n    \"backswing_frames\": [450, 1200, 2100, 3050, 3900],\n    \"contact_frames\": [520, 1270, 2170, 3120, 3970],\n    \"num_swings\": 5,\n    \"detection_config\": {\n        \"savgol_window\": 9,\n        \"peak_prominence\": 300,\n        \"peak_distance\": 300\n    },\n    \"timestamp\": \"2024-11-16T14:30:00Z\"\n}\n```\n:::\n\n\n## Hand Finder Result\n\n::: {#87931fd6 .cell execution_count=5}\n``` {.python .cell-code}\n{\n    \"video_name\": \"IMG_1016\",\n    \"hand_frames\": [[3950, 4100], null, [5200, 5350]],\n    \"representative_frames\": [4025, null, 5275],\n    \"raised_side\": [\"LEFT\", null, \"LEFT\"],\n    \"classifications\": [\"scored_swing\", \"no_hand_raise\", \"scored_swing\"],\n    \"finger_counts\": [4, null, 3]\n}\n```\n:::\n\n\n- `hand_frames`: `[start, end]` frame range of hand raise per swing, or `null` if none\n- `representative_frames`: Best frame for finger counting\n- `finger_counts`: Predicted number of fingers shown (score display)\n\n## DynamoDB Schema\n\nTable: `golf-swing-detections`\n\n| Attribute | Type | Description |\n|-----------|------|-------------|\n| `golfer` | String (PK) | Golfer name |\n| `video_name` | String (SK) | Video identifier |\n| `timestamp` | String | ISO 8601 detection time |\n| `num_swings` | Number | Detected swing count |\n| `backswing_frames` | List[Number] | Apex frame indices |\n| `contact_frames` | List[Number] | Impact frame indices |\n| `finger_predictions` | List[Object] | Added by post_processing |\n\n## S3 Key Patterns\n\n::: {#35316465 .cell execution_count=6}\n\n::: {.cell-output .cell-output-stdout}\n```\nKey Pattern                                        Description\n────────────────────────────────────────────────── ──────────────────────────────\n{golfer}/raw/{filename}.MOV                        Original iPhone upload\n{golfer}/processed/{filename}.mp4                  Transcoded H.264 CFR\n{golfer}/keypoints/{filename}.pkl                  ViTPose keypoints\n{golfer}/detection/{filename}.json                 Swing detection results\n{golfer}/fingers/{filename}.json                   Finger predictions\n{golfer}/frames/{filename}_frame_{N}.jpg           Skeleton overlay frames\n{golfer}/output/{filename}_grid.jpg                Swing grid visualization\n{golfer}/analysis/{golfer}_{day}.png               Biomechanical comparison plot\n```\n:::\n:::\n\n\n",
    "supporting": [
      "data_files"
    ],
    "filters": [],
    "includes": {}
  }
}