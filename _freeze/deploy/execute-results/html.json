{
  "hash": "60775c9e812c4b4f8f8745b5c9e91179",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Deploy & Costs\"\nsubtitle: \"AMI baking, spot instances, and cost model\"\n---\n\n## Deployment Architecture\n\nTwo-phase deployment: **bake** (infrequent) and **deploy** (per-session).\n\n```{mermaid}\nflowchart LR\n    subgraph Bake[\"bake_ami.sh (rare)\"]\n        B1[\"Launch g6.xlarge<br/>on-demand\"] --> B2[\"Install PyTorch 2.8<br/>+ cu126\"]\n        B2 --> B3[\"Build ffmpeg<br/>(NVENC/NVDEC)\"]\n        B3 --> B4[\"Install mmcv-lite<br/>(4 patches)\"]\n        B4 --> B5[\"Download model<br/>weights\"]\n        B5 --> B6[\"torch.compile<br/>warmup\"]\n        B6 --> B7[\"Snapshot → AMI<br/>(~30 min)\"]\n    end\n\n    subgraph Deploy[\"deploy.sh (per session)\"]\n        D1[\"Read AMI ID\"] --> D2[\"Create SQS + DLQ\"]\n        D2 --> D3[\"Configure S3→SQS<br/>triggers\"]\n        D3 --> D4[\"Upload scripts<br/>to S3\"]\n        D4 --> D5[\"Launch spot<br/>instance\"]\n        D5 --> D6[\"user-data:<br/>S3 pull + start\"]\n    end\n\n    Bake --> Deploy\n```\n\n**AMI bake**: Only needed when deps change (PyTorch version, mmcv, ffmpeg, model weights).\n\n**Code deploys**: Just `deploy.sh` — uploads `worker.py` and `fast_label.py` to S3. Instance pulls fresh scripts at boot via `cmp -s` (preserves inductor cache if code unchanged).\n\n## AMI Stack\n\nThe custom AMI includes:\n\n| Component | Version | Notes |\n|-----------|---------|-------|\n| PyTorch | 2.8+cu126 | cu124 builds don't exist for 2.8 |\n| mmcv-lite | 2.2.0 | 4 patches for torch 2.8 compat |\n| ffmpeg | custom build | NVENC + NVDEC support |\n| ViTPose-Huge | — | ~632M params, pre-cached weights |\n| RTMDet-M | — | Person detector, pre-cached weights |\n| numpy | <2 | Required for xtcocotools |\n\n### mmcv-lite Patches\n\nFull mmcv can't be built (setuptools removed `pkg_resources`) and prebuilt wheels are ABI-incompatible with torch 2.8. mmcv-lite is pure Python but needs 4 patches:\n\n::: {#188a35f6 .cell execution_count=1}\n``` {.python .cell-code}\n# Patch 1: ext_loader.py — stub namedtuple for missing _ext module\n# Patch 2: nms.py — torchvision.ops.nms fallback (RTMDet needs it)\n# Patch 3: mmpose heads/__init__.py — skip EDPoseHead import\n# Patch 4: mmengine checkpoint.py — weights_only=False for torch 2.6+\n```\n:::\n\n\n## Instance Lifecycle\n\n```{mermaid}\nstateDiagram-v2\n    [*] --> Launching: deploy.sh\n    Launching --> Booting: spot fulfilled\n    Booting --> Importing: user-data runs\n    Importing --> Loading: Python imports (~91s cold EBS)\n    Loading --> Polling: model loaded (~15s)\n    Polling --> Processing: SQS message received\n    Processing --> Polling: video done, check queue\n    Polling --> Idle: no messages\n    Idle --> Terminated: idle timeout\n    Terminated --> [*]\n```\n\nAuto-terminate on idle prevents paying for GPU time when the queue is empty.\n\n## Cost Model\n\n::: {#01edc8f9 .cell execution_count=2}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.use(\"Agg\")\n\n# Cost breakdown per 5-min video\ncomponents = [\"EC2 spot\\n(g6.2xlarge)\", \"S3 storage\\n(GET/PUT)\", \"Lambda\\n(detection)\", \"Lambda\\n(post-proc)\", \"DynamoDB\"]\ncosts = [0.035, 0.003, 0.001, 0.001, 0.0001]\ncolors = [\"#e74c3c\", \"#3498db\", \"#2ecc71\", \"#2ecc71\", \"#f39c12\"]\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n\n# Pie chart\nax1.pie(costs, labels=components, colors=colors, autopct=\"%1.1f%%\", startangle=90)\nax1.set_title(f\"Cost per video: ${sum(costs):.3f}\")\n\n# Monthly projection\nvideos_per_month = [10, 50, 100, 200, 500]\nmonthly_cost = [v * sum(costs) for v in videos_per_month]\nax2.bar([str(v) for v in videos_per_month], monthly_cost, color=\"#3498db\", alpha=0.8)\nax2.set_xlabel(\"Videos / month\")\nax2.set_ylabel(\"Monthly cost ($)\")\nax2.set_title(\"Projected Monthly Cost\")\nfor i, (v, c) in enumerate(zip(videos_per_month, monthly_cost)):\n    ax2.text(i, c + 0.1, f\"${c:.2f}\", ha=\"center\", fontsize=9)\n\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\n| Metric | Value |\n|--------|-------|\n| Instance | g6.2xlarge spot @ $0.47/hr |\n| Per 5-min video | ~$0.04 |\n| Throughput | ~8-11 videos/hr |\n| Cost per frame | ~$0.000003 |\n\n## EBS Cold-Start Problem\n\nFresh AMI instances read from EBS at **12 MB/s** (lazy-loading S3 snapshots) vs 125 MB/s warm:\n\n| Storage | Read Speed | Use |\n|---------|-----------|-----|\n| Root EBS (gp3) | 12 MB/s cold → 500 MB/s warm | Python packages (~14.5 GB) |\n| NVMe instance store | 1.6 GB/s | Unused (419 GB available) |\n\nThe 91s Python import time is dominated by cold EBS reads. First video warms the page cache; subsequent videos are normal speed.\n\n## AWS Resources\n\n| Resource | Service | Name |\n|----------|---------|------|\n| Video storage | S3 | `golf-swing-data` |\n| Label queue | SQS | `golf-video-label` |\n| Label worker | EC2 | g6.2xlarge spot |\n| Swing detection | Lambda | swing_detection |\n| Post-processing | Lambda | post_processing |\n| Detection results | DynamoDB | `golf-swing-detections` |\n| Container images | ECR | `golf-mmpose-labeler` |\n\n",
    "supporting": [
      "deploy_files"
    ],
    "filters": [],
    "includes": {}
  }
}