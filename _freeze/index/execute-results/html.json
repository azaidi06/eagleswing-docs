{
  "hash": "26ff2bb161c177edde1b47731b1c6edb",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Golf Swing Analysis Pipeline\"\nsubtitle: \"End-to-end video processing: raw iPhone footage â†’ biomechanical analysis\"\n---\n\n## What This Does\n\nTakes raw golf videos (iPhone HEVC, variable frame rate) through 5 stages to produce swing-by-swing biomechanical analysis:\n\n```\nPhone upload â†’ ingest â†’ label_videos â†’ swing_detection â†’ analyze\n               (HTTPS)   (EC2 GPU)      (Lambda)         (CLI/Streamlit)\n```\n\nA 5-minute 60fps video (~19K frames) processes end-to-end in **~6 minutes** at **~$0.04/video**.\n\n## Architecture\n\n```{mermaid}\nflowchart TD\n    Phone[\"ðŸ“± iPhone\"] -->|\".MOV upload\"| AppS3[\"S3: golf-app-storage\"]\n    AppS3 -->|\"S3 event\"| IngestQ[\"SQS: golf-app-ingest\"]\n    IngestQ --> Ingest[\"Lambda: ingest<br/>(cross-account copy)\"]\n    Ingest -->|\".MOV â†’ /raw/\"| S3[\"S3: golf-swing-data\"]\n\n    S3 -->|\"S3 event (.MOV/.mp4)\"| LabelQ[\"SQS: golf-video-label\"]\n    LabelQ --> EC2[\"EC2 g6.2xlarge (L4 GPU)<br/>worker.py polls SQS\"]\n\n    EC2 -->|\"NVENC transcode\"| S3proc[\"S3: /processed/*.mp4\"]\n    EC2 -->|\"ViTPose-Huge\"| S3kp[\"S3: /keypoints/*.pkl\"]\n\n    S3kp -->|\"S3 event (.pkl)\"| DetectLambda[\"Lambda: swing_detection<br/>~13s signal processing\"]\n    DetectLambda --> S3det[\"S3: /detection/*.json\"]\n    DetectLambda --> DDB[\"DynamoDB:<br/>golf-swing-detections\"]\n\n    S3det -->|\"S3 event (.json)\"| PostLambda[\"Lambda: post_processing<br/>fingers + frames\"]\n    PostLambda --> S3out[\"S3: /fingers/, /frames/, /output/\"]\n    PostLambda --> Pushover[\"ðŸ“± Pushover notification\"]\n\n    Analyze[\"Lambda/CLI: analyze\"] --> S3analysis[\"S3: /analysis/\"]\n\n    style EC2 fill:#f9f,stroke:#333,stroke-width:2px\n    style DetectLambda fill:#bbf,stroke:#333\n    style PostLambda fill:#bbf,stroke:#333\n```\n\n## Modules at a Glance\n\n| Module | Runtime | What it does |\n|--------|---------|-------------|\n| `ingest/` | Lambda | Receives phone uploads, copies to pipeline S3 bucket |\n| `label_videos/` | EC2 GPU (spot) | NVENC transcode + ViTPose-Huge pose estimation |\n| `swing_detection/` | Lambda | Signal processing on keypoints â†’ backswing/contact detection |\n| `hand_finder/` | Lambda | Detects post-swing hand raises, predicts finger count |\n| `post_processing/` | Lambda | Extracts frames, generates overlays, sends notifications |\n| `analyze/` | Lambda/CLI/Streamlit | Biomechanical comparison, SPM analysis, AI insights |\n\n## Performance Summary\n\n| Stage | Time | Hardware |\n|-------|------|----------|\n| Transcode (NVENC) | ~10s | L4 GPU hardware encoder |\n| Labeling (turbo) | ~5.5 min | 57.5 fps, torch.compile + NVDEC |\n| Swing Detection | ~13s | Lambda CPU (numpy/scipy) |\n| **End-to-end** | **~6 min** | **~$0.04/video on spot** |\n\n## GPU Hardware Utilization\n\nThe L4 has three independent silicon blocks â€” using one doesn't steal from the others:\n\n| Block | Transcode Phase | Labeling Phase |\n|-------|----------------|----------------|\n| **NVDEC** (decode) | Decode HEVC input | Decode H.264 frames |\n| **CUDA** (compute) | Idle | RTMDet + ViTPose inference |\n| **NVENC** (encode) | Encode H.264 output | Idle |\n\nAll three blocks get used across the pipeline. NVDEC does double duty â€” first for transcode input, then for frame decode during labeling.\n\n## Codebase\n\n::: {#cbe14f9e .cell execution_count=1}\n\n::: {.cell-output .cell-output-stdout}\n```\ningest                1 files     85 lines  2 tests\nlabel_videos          2 files   1075 lines  3 tests\nswing_detection       6 files    809 lines  2 tests\nhand_finder           4 files    691 lines  0 tests\npost_processing       3 files    346 lines  2 tests\nanalyze               6 files   2025 lines  1 tests\n```\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}